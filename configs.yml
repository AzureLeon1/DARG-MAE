cora:
  lr: 0.001
  lr_mask: 1e-05
  lr_sub_mask: 0.0001
  sub_mask_weight: 0.8
  sub_avg_node_num: 3
  uniformity_dim: 256
  encoder: gat
  decoder: gat
  mask_encoder: gin
  sub_mask_encoder: gin
  lr_f: 0.005
  num_hidden: 512
  num_heads: 2
  num_layers: 2
  max_epoch: 500
  max_epoch_f: 300
  weight_decay: 0.00001
  weight_decay_f: 0.01
  mask_rate: 0.25
  belta: 1.0
  emb_dim: 16
  lamda: 0.00001
  alpha_0: 0.9
  alpha_T: 1.0
  gamma: 0.8
  in_drop: 0.2
  replace_rate: 0.05
  drop_edge_rate: 0.1
  alpha_l: 2.0
  norm: layernorm
  residual: False
  scheduler: True
  linear_prob: True
  activation: prelu
  pooling: mean
  batch_size: 8

citeseer:
  lr: 0.001
  lr_mask: 0.0001
  lr_sub_mask: 0.001
  sub_mask_weight: 0.5
  sub_avg_node_num: 5
  uniformity_dim: 256
  encoder: gat
  decoder: gat
  mask_encoder: gat
  sub_mask_encoder: gat
  lr_f: 0.01
  num_hidden: 512
  num_heads: 2
  num_layers: 2
  max_epoch: 300
  max_epoch_f: 300
  weight_decay: 0.0002
  weight_decay_f: 0.01
  mask_rate: 0.5
  belta: 1.0
  emb_dim: 16
  lamda: 0.0005
  alpha_0: 0.2
  alpha_T: 0.3
  gamma: 1.0
  in_drop: 0.2
  replace_rate: 0.1
  drop_edge_rate: 0.0
  alpha_l: 1.0
  norm: layernorm
  residual: False
  scheduler: True
  linear_prob: True
  activation: prelu
  pooling: mean
  batch_size: 32

pubmed:
  lr: 0.001
  lr_mask: 0.0001
  lr_sub_mask: 0.001
  sub_mask_weight: 0.4
  sub_avg_node_num: 5
  uniformity_dim: 64
  encoder: gin
  decoder: gin
  mask_encoder: gat
  sub_mask_encoder: gat
  lr_f: 0.01
  num_hidden: 1024
  num_heads: 2
  num_layers: 1
  max_epoch: 1000
  max_epoch_f: 300
  weight_decay: 1e-05
  weight_decay_f: 0.0
  mask_rate: 0.75
  belta: 0.001
  emb_dim: 16
  lamda: 0.0005
  alpha_0: 0.7
  alpha_T: 1.0
  gamma: 1.0
  in_drop: 0.2
  replace_rate: 0.0
  drop_edge_rate: 0.0
  alpha_l: 3.0
  norm: layernorm
  residual: False
  scheduler: True
  linear_prob: True
  activation: prelu
  pooling: mean
  batch_size: 32

ogbn-arxiv:
  lr: 0.001
  lr_mask: 1e-05
  lr_sub_mask: 1e-05
  sub_mask_weight: 0.7
  sub_avg_node_num: 5
  uniformity_dim: 16
  encoder: gat
  decoder: gat
  mask_encoder: gat
  sub_mask_encoder: gat
  lr_f: 0.01
  num_hidden: 1024
  num_heads: 4
  num_layers: 3
  max_epoch: 1000
  max_epoch_f: 600
  weight_decay: 0.0
  weight_decay_f: 0.0005
  mask_rate: 0.5
  belta: 1.0
  emb_dim: 16
  lamda: 0.00005
  alpha_0: 0.7
  alpha_T: 1.0
  gamma: 1.0
  in_drop: 0.2
  replace_rate: 0.0
  drop_edge_rate: 0.5
  alpha_l: 3.0
  norm: layernorm
  residual: False
  scheduler: True
  linear_prob: True
  activation: prelu
  pooling: mean
  batch_size: 32

ppi:
  lr: 0.0001
  lr_mask: 1e-05
  lr_sub_mask: 1e-05
  sub_mask_weight: 0.9
  sub_avg_node_num: 5
  uniformity_dim: 64
  encoder: gat
  decoder: gat
  mask_encoder: gat
  sub_mask_encoder: gat
  lr_f: 0.005
  num_hidden: 1024
  num_heads: 4
  num_layers: 3
  max_epoch: 1000
  max_epoch_f: 1500
  weight_decay: 0.0
  weight_decay_f: 0.0
  mask_rate: 0.5
  belta: 1.0
  emb_dim: 16
  lamda: 0.00005
  alpha_0: 0.0
  alpha_T: 0.3
  gamma: 1.0
  in_drop: 0.2
  replace_rate: 0.1
  drop_edge_rate: 0.0
  alpha_l: 3.0
  norm: layernorm
  residual: True
  scheduler: True
  linear_prob: True
  activation: prelu
  pooling: mean
  batch_size: 32

reddit:
  lr: 1e-05
  lr_mask: 1e-05
  lr_sub_mask: 1e-05
  sub_mask_weight: 0.8
  sub_avg_node_num: 7
  uniformity_dim: 4
  encoder: gin
  decoder: gin
  mask_encoder: gin
  sub_mask_encoder: gin
  lr_f: 0.01
  num_hidden: 1024
  num_heads: 4
  num_layers: 3
  max_epoch: 500
  max_epoch_f: 500
  weight_decay: 0.0002
  weight_decay_f: 0.0005
  mask_rate: 0.5
  belta: 1.0
  emb_dim: 16
  lamda: 0.00001
  alpha_0: 0.7
  alpha_T: 1.0
  gamma: 1.0
  in_drop: 0.2
  replace_rate: 0.15
  drop_edge_rate: 0.5
  alpha_l: 3.0
  norm: layernorm
  residual: True
  scheduler: True
  linear_prob: True
  activation: prelu
  pooling: mean
  batch_size: 32

corafull:
  lr: 0.001
  lr_mask: 0.0001
  lr_sub_mask: 1e-05
  sub_mask_weight: 0.1
  sub_avg_node_num: 4
  uniformity_dim: 128
  encoder: gat
  decoder: gat
  mask_encoder: gin
  sub_mask_encoder: gin
  lr_f: 0.01
  num_hidden: 1024
  num_heads: 4
  num_layers: 2
  max_epoch: 500
  max_epoch_f: 600
  weight_decay: 0.0002
  weight_decay_f: 0.0001
  mask_rate: 0.25
  belta: 1.0
  emb_dim: 16
  lamda: 1.0
  alpha_0: 0.5
  alpha_T: 1.0
  gamma: 1.0
  in_drop: 0.2
  replace_rate: 0.0
  drop_edge_rate: 0.0
  alpha_l: 3.0
  norm: layernorm
  residual: False
  scheduler: True
  linear_prob: True
  activation: prelu
  pooling: mean
  batch_size: 32

flickr:
  lr: 0.0001
  lr_mask: 1e-05
  lr_sub_mask: 1e-05
  sub_mask_weight: 0.1
  sub_avg_node_num: 5
  uniformity_dim: 64
  encoder: gat
  decoder: gat
  mask_encoder: gat
  sub_mask_encoder: gat
  lr_f: 0.01
  num_hidden: 512
  num_heads: 2
  num_layers: 2
  max_epoch: 1000
  max_epoch_f: 600
  weight_decay: 0.0002
  weight_decay_f: 0.0001
  mask_rate: 0.75
  belta: 0.001
  emb_dim: 16
  lamda: 0.00005
  alpha_0: 0.0
  alpha_T: 1.0
  gamma: 1.0
  in_drop: 0.2
  replace_rate: 0.0
  drop_edge_rate: 0.1
  alpha_l: 3.0
  norm: layernorm
  residual: False
  scheduler: True
  linear_prob: True
  activation: prelu
  pooling: mean
  batch_size: 32

wikics:
  lr: 0.0001
  lr_mask: 0.0001
  lr_sub_mask: 0.001
  sub_mask_weight: 0.5
  sub_avg_node_num: 3
  uniformity_dim: 128
  encoder: gin
  decoder: gin
  mask_encoder: gin
  sub_mask_encoder: gin
  lr_f: 0.005
  num_hidden: 1024
  num_heads: 2
  num_layers: 1
  max_epoch: 500
  max_epoch_f: 300
  weight_decay: 0.0
  weight_decay_f: 0.0
  mask_rate: 0.5
  belta: 0.001
  emb_dim: 16
  lamda: 0.001
  alpha_0: 0.5
  alpha_T: 1.0
  gamma: 1.0
  in_drop: 0.2
  replace_rate: 0.0
  drop_edge_rate: 0.0
  alpha_l: 3.0
  norm: layernorm
  residual: False
  scheduler: True
  linear_prob: True
  activation: prelu
  pooling: mean
  batch_size: 32

IMDB-BINARY:
  lr: 0.00015
  lr_mask: 0.001
  lr_sub_mask: 0.001
  sub_mask_weight: 0.2
  sub_avg_node_num: 7
  uniformity_dim: 16
  encoder: gin
  decoder: gin
  mask_encoder: gat
  sub_mask_encoder: gat
  lr_f: 0.01
  num_hidden: 256
  num_heads: 4
  num_layers: 2
  max_epoch: 60
  max_epoch_f: 500
  weight_decay: 0.0002
  weight_decay_f: 0.0
  mask_rate: 0.5
  belta: 0.01
  emb_dim: 16
  lamda: 0.001
  alpha_0: 0.0
  alpha_T: 0.6
  gamma: 1.0
  in_drop: 0.2
  replace_rate: 0.0
  drop_edge_rate: 0.0
  alpha_l: 1.0
  norm: batchnorm
  residual: False
  scheduler: False
  linear_prob: True
  activation: prelu
  pooling: mean
  batch_size: 32

IMDB-MULTI:
  lr: 0.00015
  lr_mask: 1e-05
  lr_sub_mask: 1e-05
  sub_mask_weight: 0.1
  sub_avg_node_num: 3
  uniformity_dim: 128
  encoder: gin
  decoder: gin
  mask_encoder: gat
  sub_mask_encoder: gat
  lr_f: 0.01
  num_hidden: 512
  num_heads: 2
  num_layers: 3
  max_epoch: 50
  max_epoch_f: 600
  weight_decay: 0.0002
  weight_decay_f: 0.0005
  mask_rate: 0.75
  belta: 0.001
  emb_dim: 16
  lamda: 0.00005
  alpha_0: 0.0
  alpha_T: 1.0
  gamma: 1.0
  in_drop: 0.2
  replace_rate: 0.0
  drop_edge_rate: 0.0
  alpha_l: 1.0
  norm: batchnorm
  residual: False
  scheduler: False
  linear_prob: True
  activation: prelu
  pooling: mean
  batch_size: 32

PROTEINS:
  lr: 0.00015
  lr_mask: 1e-05
  lr_sub_mask: 1e-05
  sub_mask_weight: 0.4
  sub_avg_node_num: 7
  uniformity_dim: 64
  encoder: gin
  decoder: gin
  mask_encoder: gin
  sub_mask_encoder: gin
  lr_f: 0.005
  num_hidden: 1024
  num_heads: 4
  num_layers: 3
  max_epoch: 100
  max_epoch_f: 600
  weight_decay: 0.0
  weight_decay_f: 0.0001
  mask_rate: 0.5
  belta: 0.01
  emb_dim: 16
  lamda: 0.001
  alpha_0: 0.3
  alpha_T: 0.7
  gamma: 0.8
  in_drop: 0.2
  replace_rate: 0.0
  drop_edge_rate: 0.0
  alpha_l: 1.0
  norm: batchnorm
  residual: False
  scheduler: False
  linear_prob: True
  activation: prelu
  pooling: max
  batch_size: 32

COLLAB:
  lr: 0.0001
  lr_mask: 0.001
  lr_sub_mask: 0.001
  sub_mask_weight: 0.6
  sub_avg_node_num: 5
  uniformity_dim: 4
  encoder: gin
  decoder: gin
  mask_encoder: gat
  sub_mask_encoder: gat
  lr_f: 0.005
  num_hidden: 512
  num_heads: 2
  num_layers: 1
  max_epoch: 20
  max_epoch_f: 600
  weight_decay: 0.0
  weight_decay_f: 0.0001
  mask_rate: 0.75
  belta: 0.0001
  emb_dim: 16
  lamda: 0.0005
  alpha_0: 0.0
  alpha_T: 0.4
  gamma: 1.0
  in_drop: 0.2
  replace_rate: 0.0
  drop_edge_rate: 0.0
  alpha_l: 1.0
  norm: batchnorm
  residual: False
  scheduler: True
  linear_prob: True
  activation: relu
  pooling: max
  batch_size: 32

MUTAG:
  lr: 0.001
  lr_mask: 0.001
  lr_sub_mask: 0.0001
  sub_mask_weight: 0.1
  sub_avg_node_num: 4
  uniformity_dim: 8
  encoder: gat
  decoder: gat
  mask_encoder: gat
  sub_mask_encoder: gat
  lr_f: 0.01
  num_hidden: 32
  num_heads: 2
  num_layers: 4
  max_epoch: 20
  max_epoch_f: 600
  weight_decay: 0.0002
  weight_decay_f: 0.0001
  mask_rate: 0.1
  belta: 1.0
  emb_dim: 16
  lamda: 0.001
  alpha_0: 0.0
  alpha_T: 0.5
  gamma: 0.8
  in_drop: 0.2
  replace_rate: 0.1
  drop_edge_rate: 0.0
  alpha_l: 2.0
  norm: layernorm
  residual: False
  scheduler: True
  linear_prob: True
  activation: prelu
  pooling: sum
  batch_size: 64

REDDIT-BINARY:
  lr: 0.00015
  lr_mask: 0.0001
  lr_sub_mask: 1e-05
  sub_mask_weight: 0.2
  sub_avg_node_num: 4
  uniformity_dim: 32
  encoder: gin
  decoder: gin
  mask_encoder: gin
  sub_mask_encoder: gin
  lr_f: 0.01
  num_hidden: 1024
  num_heads: 4
  num_layers: 3
  max_epoch: 100
  max_epoch_f: 600
  weight_decay: 0.0
  weight_decay_f: 0.0001
  mask_rate: 0.75
  belta: 0.01
  emb_dim: 16
  lamda: 0.001
  alpha_0: 0.0
  alpha_T: 0.4
  gamma: 1.0
  in_drop: 0.2
  replace_rate: 0.1
  drop_edge_rate: 0.0
  alpha_l: 2.0
  norm: layernorm
  residual: False
  scheduler: True
  linear_prob: True
  activation: prelu
  pooling: sum
  batch_size: 8
